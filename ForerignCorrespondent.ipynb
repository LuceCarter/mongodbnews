{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the articles data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Third-party\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError, ConnectionFailure\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>artDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Posle nesreće izazvane obrušavanjem nadstrešn...</td>\n",
       "      <td>UKCV: Nema novih žrtava, troje povređenih i da...</td>\n",
       "      <td>2024-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urušavanje nadstrešnice Železničke stanice u ...</td>\n",
       "      <td>Arhitekta: Urušavanje dela Železničke stanice ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centar za lokalnu samoupravu (CLS) saopštio j...</td>\n",
       "      <td>CLS: JKP Gradska čistoća duguje budžetu Beogra...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zvaničnici Evropske unije i više država, među...</td>\n",
       "      <td>Zvaničnici EU i više država izrazili saučešće ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pravni fakultet u Beogradu saopštio je da inf...</td>\n",
       "      <td>Pravni fakultet: Koleginica nagazila na utični...</td>\n",
       "      <td>2024-10-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0   Posle nesreće izazvane obrušavanjem nadstrešn...   \n",
       "1   Urušavanje nadstrešnice Železničke stanice u ...   \n",
       "2   Centar za lokalnu samoupravu (CLS) saopštio j...   \n",
       "3   Zvaničnici Evropske unije i više država, među...   \n",
       "4   Pravni fakultet u Beogradu saopštio je da inf...   \n",
       "\n",
       "                                               title     artDate  \n",
       "0  UKCV: Nema novih žrtava, troje povređenih i da...  2024-11-02  \n",
       "1  Arhitekta: Urušavanje dela Železničke stanice ...  2024-11-01  \n",
       "2  CLS: JKP Gradska čistoća duguje budžetu Beogra...  2024-11-01  \n",
       "3  Zvaničnici EU i više država izrazili saučešće ...  2024-11-01  \n",
       "4  Pravni fakultet: Koleginica nagazila na utični...  2024-10-31  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "articles = pd.read_csv('fa_articles.csv', encoding='utf-8')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Embedić model for Serbian language embeddings\n",
    "# !pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm  # Changed this import\n",
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the embeddings for Serbian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('djovak/embedic-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for concatenating the article's title and content and passing to the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df: pd.DataFrame, batch_size: int = 32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate embeddings for concatenated title and content using Embedić.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'title' and 'content' columns\n",
    "        batch_size: Number of texts to process at once\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added 'embedding' column\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_emb = df.copy()\n",
    "    \n",
    "    # Concatenate title and content\n",
    "    print(\"Concatenating title and content...\")\n",
    "    df_emb['text_for_embedding'] = df_emb['title'] + \" \" + df_emb['content']\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    # Convert texts to list for batch processing\n",
    "    texts = df_emb['text_for_embedding'].tolist()\n",
    "    \n",
    "    # Process in batches with progress bar\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_text = texts[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch_text)\n",
    "        embeddings.extend(batch_embeddings.tolist())\n",
    "    \n",
    "    # Add embeddings to dataframe\n",
    "    df_emb['embedding'] = embeddings\n",
    "    \n",
    "    # Remove temporary concatenated text column\n",
    "    df_emb = df_emb.drop('text_for_embedding', axis=1)\n",
    "    \n",
    "    print(f\"Generated embeddings for {len(df_emb)} articles\")\n",
    "    print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "    \n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating title and content...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ed5399d1a645efa0c6879acfa2f488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 873 articles\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "df_with_embeddings = generate_embeddings(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the generated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape: (873, 4)\n",
      "\n",
      "Columns: ['content', 'title', 'artDate', 'embedding']\n",
      "\n",
      "Sample embedding (first 5 dimensions):\n",
      "[0.036100856959819794, -0.03139951825141907, -0.02158968150615692, -0.02952212281525135, 0.06143483147025108]\n",
      "\n",
      "All embeddings have same dimension: True\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "# Preview the results\n",
    "print(\"\\nDataFrame shape:\", df_with_embeddings.shape)\n",
    "print(\"\\nColumns:\", df_with_embeddings.columns.tolist())\n",
    "\n",
    "# Sample embedding vector (first 5 dimensions)\n",
    "print(\"\\nSample embedding (first 5 dimensions):\")\n",
    "print(df_with_embeddings['embedding'].iloc[0][:5])\n",
    "\n",
    "# Verify embedding dimensions are consistent\n",
    "embedding_lengths = df_with_embeddings['embedding'].apply(len)\n",
    "print(\"\\nAll embeddings have same dimension:\", embedding_lengths.nunique() == 1)\n",
    "print(\"Embedding dimension:\", embedding_lengths.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mongodb(df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame rows to MongoDB documents.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with embeddings\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries ready for MongoDB insertion\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        document = {           \n",
    "            'title': row['title'],\n",
    "            'content': row['content'],\n",
    "            'date': row['artDate'],  # Assuming you have a date column\n",
    "            'embedding': row['embedding'],\n",
    "            'metadata': {\n",
    "                'embedding_model': 'djovak/embedic-large',\n",
    "                'created_at': datetime.now(),\n",
    "                'last_updated': datetime.now()\n",
    "            }\n",
    "        }\n",
    "        documents.append(document)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1440c513dd70455a9cb98cd6af8bee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/873 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared 873 documents for MongoDB insertion\n",
      "\n",
      "Sample document structure (excluding embedding vector):\n",
      "{\n",
      "  \"title\": \"UKCV: Nema novih \\u017ertava, troje povre\\u0111enih i dalje u te\\u0161kom stanju\",\n",
      "  \"content\": \" Posle nesre\\u0107e izazvane obru\\u0161avanjem nadstre\\u0161nice na \\u017delezni\\u010dkoj stanici u Novom Sadu, novih \\u017ertava nema, a troje povre\\u0111enih je u te\\u0161kom op\\u0161tem stanju, potvr\\u0111eno je za Tanjug u Univerzitetskom klini\\u010dkom centru Vojvodine (UKCV). \\u201eTroje povre\\u0111enih koji su ju\\u010de primljeni u UKCV i dalje su u te\\u0161kom stanju, na intenzivnoj nezi\\u201c, re\\u010deno je iz Pres-slu\\u017ebe Klini\\u010dkog centra za Tanjug. Portparolka De\\u010dje bolnice Andrea \\u0110ureti\\u0107 rekla je da ni sino\\u0107 u tu bolnicu nisu primljene dve devoj\\u010dice. Povezane vesti U Srbiji danas Dan \\u017ealosti, u Novom Sadu trodnevna Vesti 08:16 27 Vesti 08:16 27 Zavr\\u0161ena akcija spasavanja: 14 stradalih i troje te\\u0161ko povre\\u0111enih u uru\\u0161avanju nadstre\\u0161nice na \\u017delezni\\u010dkoj stanici Vesti 23:31 602 Vesti 23:31 602 \\u201ePovodom informacije koju prenose mediji da su dve devoj\\u010dice preminule, mi ne znamo da li su devoj\\u010dice bile na \\u017delezni\\u010dkoj stanici i mo\\u017eda su me\\u0111u 14 poginulih, ali u bolnicu nisu primljene i nema novih \\u017ertvi\\u201c, re\\u010deno je iz De\\u010dje bolnice u Novom Sadu. Za dalje informacije za javnost, nadle\\u017ena je policija. Mediji prenose da su tokom no\\u0107i dve devoj\\u010dice preminule u Urgentnom centru u Novom Sadu. Prema poslednjim zvani\\u010dnim podacima, \\u010detrnaestoro ljudi je ju\\u010de poginulo, a troje je povre\\u0111eno u nesre\\u0107i izazvanoj uru\\u0161avanjem nadstre\\u0161nice na staroj zgradi \\u017delezni\\u010dke stanice u Novom Sadu. Vlada Srbije proglasila je 2. novembar za Dan \\u017ealosti zbog ove tragedije, dok je u Novom Sadu progla\\u0161ena trodnevna \\u017ealost.\",\n",
      "  \"date\": \"2024-11-02\",\n",
      "  \"embedding\": \"<embedding vector with 1024 dimensions>\",\n",
      "  \"metadata\": {\n",
      "    \"embedding_model\": \"djovak/embedic-large\",\n",
      "    \"created_at\": \"2024-11-19 22:32:50.931614\",\n",
      "    \"last_updated\": \"2024-11-19 22:32:50.931614\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to MongoDB documents\n",
    "mongodb_documents = prepare_for_mongodb(df_with_embeddings)\n",
    "print(f\"\\nPrepared {len(mongodb_documents)} documents for MongoDB insertion\")\n",
    "print(\"\\nSample document structure (excluding embedding vector):\")\n",
    "sample_doc = mongodb_documents[0].copy()\n",
    "sample_doc['embedding'] = f\"<embedding vector with {len(sample_doc['embedding'])} dimensions>\"\n",
    "print(json.dumps(sample_doc, default=str, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data into the MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection setup\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\")\n",
    "DB_NAME = os.getenv(\"DB_NAME_1\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "if not all([MONGODB_URI, DB_NAME, COLLECTION_NAME]):\n",
    "    raise ValueError(\"Missing required environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully connected to MongoDB\n"
     ]
    }
   ],
   "source": [
    "def get_mongodb_connection():\n",
    "    \"\"\"\n",
    "    Create and return MongoDB client, database and collection objects.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (MongoClient, Database, Collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        # Test connection\n",
    "        client.admin.command('ping')\n",
    "        logger.info(\"Successfully connected to MongoDB\")\n",
    "        \n",
    "        db = client[DB_NAME]\n",
    "        collection = db[COLLECTION_NAME]\n",
    "        return client, db, collection\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to connect to MongoDB. Error: {str(e)}\")\n",
    "        raise ConnectionFailure(f\"MongoDB connection failed: {str(e)}\")\n",
    "\n",
    "client, db, collection = get_mongodb_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for inserting data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_documents_to_mongodb(documents: List[Dict], \n",
    "                              batch_size: int = 1000) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Insert documents into MongoDB in batches.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of documents to insert\n",
    "        batch_size: Number of documents to insert in each batch\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (successful insertions, failed insertions)\n",
    "    \"\"\"\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    print(f\"Starting insertion of {len(documents)} documents...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(documents), batch_size)):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        try:\n",
    "            # Insert batch with ordered=False for better performance\n",
    "            result = collection.insert_many(batch, ordered=False)\n",
    "            successful += len(result.inserted_ids)\n",
    "        except BulkWriteError as e:\n",
    "            # Handle partial failures in batch\n",
    "            successful += e.details['nInserted']\n",
    "            failed += len(batch) - e.details['nInserted']\n",
    "            print(f\"Batch {i//batch_size + 1} had {e.details['nInserted']} successful and \"\n",
    "                  f\"{len(batch) - e.details['nInserted']} failed insertions\")\n",
    "    \n",
    "    return successful, failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing the collection and inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting insertion of 873 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f5db6962ad43ad9e404f18ea9ba397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insertion complete:\n",
      "Successfully inserted: 873 documents\n",
      "Failed insertions: 0 documents\n"
     ]
    }
   ],
   "source": [
    "collection.delete_many({})\n",
    "# Insert documents\n",
    "successful, failed = insert_documents_to_mongodb(mongodb_documents)\n",
    "print(f\"\\nInsertion complete:\")\n",
    "print(f\"Successfully inserted: {successful} documents\")\n",
    "print(f\"Failed insertions: {failed} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'numDimensions': 1024,\n",
       "   'path': 'embedding',\n",
       "   'similarity': 'cosine',\n",
       "   'type': 'vector'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"numDimensions\": 1024,\n",
    "      \"path\": \"embedding\",\n",
    "      \"similarity\": \"cosine\",\n",
    "      \"type\": \"vector\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(\n",
    "    connection_string: str,\n",
    "    database_name: str,\n",
    "    collection_name: str,\n",
    "    index_name: str = \"vector_index\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a vector search index in MongoDB using PyMongo.\n",
    "    \n",
    "    Args:\n",
    "        connection_string: MongoDB connection string\n",
    "        database_name: Name of the database\n",
    "        collection_name: Name of the collection\n",
    "        index_name: Name of the vector index\n",
    "    \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    client = client\n",
    "    \n",
    "    # Get database and collection\n",
    "    db = db\n",
    "    collection = collection\n",
    "    \n",
    "    # Define the index configuration\n",
    "    index_config = {\n",
    "        \"name\": index_name,\n",
    "        \"definition\": {\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"numDimensions\": 1024,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"similarity\": \"cosine\",\n",
    "                    \"type\": \"vector\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Create the vector search index\n",
    "        collection.create_search_index(index_config)\n",
    "        print(f\"Successfully created vector index '{index_name}'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector index: {str(e)}\")        \n",
    "    finally:\n",
    "        client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection Information:\n",
      "Total documents: 873\n",
      "Indexes: {'_id_': {'v': 2, 'key': [('_id', 1)]}, 'articleDate_1': {'v': 2, 'key': [('articleDate', 1)]}, 'title_text_content_text': {'v': 2, 'key': [('_fts', 'text'), ('_ftsx', 1)], 'weights': SON([('content', 1), ('title', 1)]), 'default_language': 'english', 'language_override': 'language', 'textIndexVersion': 3}}\n"
     ]
    }
   ],
   "source": [
    "# Create standard indexes for better query performance\n",
    "\n",
    "#collection.create_index(\"articleDate\")\n",
    "#collection.create_index([(\"title\", \"text\"), (\"content\", \"text\")])\n",
    "\n",
    "# Verify the setup\n",
    "print(\"\\nCollection Information:\")\n",
    "print(f\"Total documents: {collection.count_documents({})}\")\n",
    "print(f\"Indexes: {collection.index_information()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b811b514c11d45a18b3c67d2a3bc9dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Novi Sad\n",
      "================================================================================\n",
      "\n",
      "1. Sutra otvaranje 24. Salona arhitekture Novi Sad\n",
      "Score: 0.853\n",
      "\n",
      "Excerpt: Micki/Wikimedia Commons Novosadski Salon arhitekture biće svečano otvoren u subotu, 26. oktobra, u 19 sati u Muzeju savremene umetnosti Vojvodine. Salon arhitekture Novi Sad je međunarodna smotra aktu...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Novaković : Za tragediju u Novom Sadu krivi Ministarstvo infrastrukture, Železnice Srbije i Gradska uprava, odgovorni da podnesu ostavke\n",
      "Score: 0.841\n",
      "\n",
      "Excerpt: Sanja Kosović/ \"Za tregediju u Novom Sadu svi nadležni moraju da preuzmu odgovornost - od Ministarstva infrastrukture, Javnog preduzeća Železnice Srbije, do Gradske uprave... Umesto da sami preuzmu od...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Građani i u Podgorici pale sveće za stradale u Novom Sadu\n",
      "Score: 0.841\n",
      "\n",
      "Excerpt: TANJUG/ NENAD MIHAJLOVIĆ Ispred Ambasade Srbije u Podgorici večeras je organizovano paljenje sveća za stradale u nesreći u Novom Sadu u kojoj je život izgubilo 14 ljudi, nakon pada nadstrešnice na Žel...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. (VIDEO) Bagerima se podiže otpala betonska konstrukcija na Železničkoj u Novom Sadu\n",
      "Score: 0.837\n",
      "\n",
      "Excerpt:  U urušavanju nadstrešnice Železničke zgrade u Novom Sadu stradala je najmanje jedna osoba, a više njih je povređeno. Zgrada je nadavno rekonstruisana, i to dva puta. Svečano je otvorena 5. jula. Obra...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. „Kada sam čula prasak, mislila sam da je bombardovanje“: Šta kažu Novosađani za  o nesreći\n",
      "Score: 0.836\n",
      "\n",
      "Excerpt: Dan nakon što se dogodila tragedija u Novom Sadu, stanovnici ovog grada su i dalje potreseni ovim događajem. Za  su podelili kako se osećaju i šta misle o obrušavanju nadstrešnice na Železničkoj stani...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Grad Novi Sad: Porodice iz Bangladeša biće useljene do kraja ove godine u stambene kontejnere\n",
      "Score: 0.836\n",
      "\n",
      "Excerpt:  Crveni krst Novog Sada pokrenuo je postupak javne nabavke stambenih kontejnera, a porodice iz neformalnog naselja Bangladeš će do kraja ove godine biti useljene u te stambene kontejnere, navodi Grad ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdec454a9004dcf8b767ac1e423b854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Lithium\n",
      "================================================================================\n",
      "\n",
      "1. Miki Krstović o litijumu: Ukoliko je zlo, siguran sam da narod nije toliko lud da to dozvoli\n",
      "Score: 0.848\n",
      "\n",
      "Excerpt: Glumac Miodrag Krstović, gostujući u \"360 stepeni\", rekao je da o litijumu \"treba da odlučuje struka, a ne glumci ili političari\", kao i da je siguran, ukoliko je iskopavanje zlo - \"da narod nije toli...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Vučković: Proširenje ponovo u fokusu EU, Srbija treba da proceni da li to može da iskoristi\n",
      "Score: 0.839\n",
      "\n",
      "Excerpt: „U ovom geopolitičkom trenutku EU je ponovo među svoje prioritete stavila proširenje. Hajde da vidimo da li to možemo da iskoristimo za ono što je naš cilj, a to je da postanemo član tog kluba“, izjav...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Kostić (Dveri): Apsolutno smo protiv rudarenja litijuma, ostajemo čvrsta opozicija\n",
      "Score: 0.836\n",
      "\n",
      "Excerpt:  Predsednik Srpskog pokreta Dveri Ivan Kostić izjavio je da je ta stranka \"apsolutno protiv rudarenja litijuma i bora i podržava sve ekološke predstavnike iz ekoloških organizacija, kao što je 'Ne dam...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Protest protiv litijuma u Valjevu 1. novembra – biće saopštene dalje akcije\n",
      "Score: 0.833\n",
      "\n",
      "Excerpt:  Advokat Branko Ivković iz Valjevskog pokreta otpora saopštio je danas da će 1. novembra u tom gradu biti organizovane demonstracije zbog namere vlasti da odobri otvaranje rudnika litijuma. Ivković je...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Valjevski pokret otpora pozvao kompaniju Euro Litijum Balkan da napusti grad do 1. novembra\n",
      "Score: 0.828\n",
      "\n",
      "Excerpt:  Konferencija za novinare Valjevskog pokreta otpora (VPO) bila je posvećena borbi protiv delovanja kanadske kompanije Euro Litijum Balkan (ELB) u valjevskoj opštini. Branko Ivković iz VPO je pozvao Va...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Protest protiv kopanja litijuma u Čačku: Kokanović objavio gde će biti sledeće blokade\n",
      "Score: 0.825\n",
      "\n",
      "Excerpt: Dok u Vršcu sve odjekuje zbog 16. rođendana Srpske napredne stranke, u Čačku se ori \"nećete kopati\", gde se održao još jedan protest protiv kopanja litijuma. Više od hiljadu ljudi protestovalo je na g...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8e57859f9a4236bcc13b0610cdce75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Freedom politics\n",
      "================================================================================\n",
      "\n",
      "1. ZLF: Poslanicima EP ukazati na izjave Ursule fon der Lajen koje su suprotne Izveštaju EK\n",
      "Score: 0.814\n",
      "\n",
      "Excerpt: REUTERS/Valdrin Xhemaj Zeleno-levi front (ZLF) saopštio je da će se obratiti svim poslaničkim grupama u Evropskom parlamentu i ukazati im na skandalozne izjave Ursule fon der Lajen (date nedavno u Beo...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Opozicija u Albaniji blokirala saobraćaj\n",
      "Score: 0.813\n",
      "\n",
      "Excerpt: Tanjug/AP Photo/Vlasov Sulaj Albanska opozicija blokirala je danas raskrsnice širom zemlje zahtevajući da aktuelnu vladu zameni tehnokratska privremena vlada pre parlamentarnih izbora sledeće godine...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Novosadska opozicija traži smenu Ognjena Dopuđe zbog incidenta u Rektoratu\n",
      "Score: 0.812\n",
      "\n",
      "Excerpt:  Poslanička grupa \"Pokret slobodnih građana - Demokratska stranka - Zajedno\" u Skupštini Vojvodine postavila je predsednici pokrajainske vlade Maji Gojković poslaničko pitanje da li će direktor Fonda ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Direktor somborskog „Zelenila“ renovirao vikendicu o trošku preduzeća, pod pritiskom opozicije podneo ostavku\n",
      "Score: 0.811\n",
      "\n",
      "Excerpt: V.d direktora JKP \"Zelenilo\" u Somboru podneo je ostavku nakon što ga je opoziciona odbornička grupa \"Živeti slobodno\" uhvatila na delu - da je renovirao i ozelenjavao vikendicu o trošku tog javnog pr...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Grbović: Podržavamo protest prosvetnih radnika, ovo je bitka svih bitaka\n",
      "Score: 0.811\n",
      "\n",
      "Excerpt:  Predsednik Pokreta slobodnih građana (PSG) Pavle Grbović izjavio je da ta stranka podržava protest prosvetnih radnika i da je dobro obrazovanje najveća razvojna šansa za državu, a da je zadovoljan i ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Danas: Opozicija kaže da je evropskim zvaničncima važnija demokratija u Gruziji nego u Srbiji\n",
      "Score: 0.810\n",
      "\n",
      "Excerpt: Kenzo Tribouillard / AFP Donedavna poslanica Evropskog parlamenta iz redova nemačkih Zelenih, Viola fon Kramon, uporedila je izborne malverzacije koje su se pre par dana dogodile u Gruziji sa onima u ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(collection, query: str, k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform semantic search using Embedić vector similarity.\n",
    "    \n",
    "    Args:\n",
    "        collection: MongoDB collection\n",
    "        query: Search query text\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for query using Embedić\n",
    "        query_embedding = model.encode(query).tolist()\n",
    "        \n",
    "        # Perform vector search\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"vector_index\",\n",
    "                    \"queryVector\": query_embedding,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"numCandidates\": 100,\n",
    "                    \"limit\": k\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"title\": 1,\n",
    "                    \"content\": 1,\n",
    "                    \"date\": 1,             \n",
    "                    \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        results = list(collection.aggregate(pipeline))\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def display_search_results(query: str, results: List[Dict]):\n",
    "    \"\"\"\n",
    "    Display search results in a readable format\n",
    "    \"\"\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. {doc['title']}\")\n",
    "        print(f\"Score: {doc['score']:.3f}\")\n",
    "        print(f\"\\nExcerpt: {doc['content'][:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Test the search\n",
    "queries = [\n",
    "    \"Novi Sad\",\"Lithium\", \"Freedom politics\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results = semantic_search(collection, query, k=6)\n",
    "    display_search_results(query, results)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\desktop\\ragmongodb\\venv\\lib\\site-packages (1.5.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\desktop\\ragmongodb\\venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\desktop\\ragmongodb\\venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\desktop\\ragmongodb\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\desktop\\ragmongodb\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def analyze_article_topics(\n",
    "    collection,\n",
    "    min_k: int = 2,\n",
    "    max_k: int = 10,\n",
    "    embedding_field: str = \"embedding\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze topics in articles stored in MongoDB using their embeddings\n",
    "    \n",
    "    Args:\n",
    "        collection: MongoDB collection object\n",
    "        min_k: Minimum number of clusters to try\n",
    "        max_k: Maximum number of clusters to try\n",
    "        embedding_field: Name of the field containing embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    # Fetch all documents\n",
    "    documents = list(collection.find(\n",
    "        {embedding_field: {\"$exists\": True}},\n",
    "        {\"title\": 1, \"content\": 1, \"date\": 1, embedding_field: 1}\n",
    "    ))\n",
    "    \n",
    "    if not documents:\n",
    "        raise ValueError(\"No documents found with embeddings\")\n",
    "    \n",
    "    # Extract embeddings and create a mapping of texts\n",
    "    embeddings = np.array([doc[embedding_field] for doc in documents])\n",
    "    \n",
    "    # Create document summaries for easier reference\n",
    "    doc_summaries = [\n",
    "        {\n",
    "            \"id\": str(doc[\"_id\"]),\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"date\": doc[\"date\"],\n",
    "            \"preview\": doc[\"content\"][:200] + \"...\"  # First 200 chars\n",
    "        }\n",
    "        for doc in documents\n",
    "    ]\n",
    "    \n",
    "    # Find optimal number of clusters\n",
    "    optimal_k, scores = get_optimal_k(embeddings, k_range=range(min_k, max_k + 1))\n",
    "    \n",
    "    # Perform clustering with optimal k\n",
    "    labels, kmeans = cluster_documents(embeddings, k=optimal_k)\n",
    "    \n",
    "    # Get representative documents for each cluster\n",
    "    central_docs = find_central_documents(embeddings, labels, doc_summaries)\n",
    "    \n",
    "    # Calculate cluster statistics\n",
    "    cluster_stats = calculate_cluster_stats(doc_summaries, labels)\n",
    "    \n",
    "    # Organize results\n",
    "    results = {\n",
    "        \"optimal_k\": optimal_k,\n",
    "        \"silhouette_scores\": scores,\n",
    "        \"cluster_assignments\": [int(label) for label in labels],\n",
    "        \"cluster_stats\": cluster_stats,\n",
    "        \"representative_documents\": central_docs,\n",
    "        \"document_mapping\": {\n",
    "            str(doc[\"_id\"]): {\n",
    "                \"cluster\": int(label),\n",
    "                \"title\": doc[\"title\"],\n",
    "                \"date\": doc[\"date\"].isoformat() if isinstance(doc[\"date\"], datetime) else doc[\"date\"]\n",
    "            }\n",
    "            for doc, label in zip(documents, labels)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Keep the helper functions from before\n",
    "def calculate_cluster_stats(doc_summaries: List[Dict], labels: np.ndarray) -> List[Dict]:\n",
    "    \n",
    "    cluster_stats = []\n",
    "    unique_labels = sorted(set(labels))\n",
    "    \n",
    "    for cluster_id in unique_labels:\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_docs = [doc for doc, is_in_cluster in zip(doc_summaries, cluster_mask) if is_in_cluster]\n",
    "        \n",
    "        dates = [\n",
    "            datetime.fromisoformat(doc[\"date\"]) if isinstance(doc[\"date\"], str) \n",
    "            else doc[\"date\"] \n",
    "            for doc in cluster_docs\n",
    "        ]\n",
    "        \n",
    "        stats = {\n",
    "            \"cluster_id\": int(cluster_id),\n",
    "            \"size\": int(sum(cluster_mask)),\n",
    "            \"earliest_date\": min(dates).isoformat(),\n",
    "            \"latest_date\": max(dates).isoformat(),\n",
    "            \"date_range_days\": (max(dates) - min(dates)).days,\n",
    "            \"sample_titles\": [doc[\"title\"] for doc in cluster_docs[:5]]\n",
    "        }\n",
    "        cluster_stats.append(stats)\n",
    "    \n",
    "    return cluster_stats\n",
    "\n",
    "def cluster_documents(embeddings, k, random_state=42):\n",
    "   \n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    return labels, kmeans\n",
    "\n",
    "def find_central_documents(embeddings, labels, doc_summaries, n_per_cluster=3):\n",
    "   \n",
    "    central_docs = {}\n",
    "    \n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_embeddings = embeddings[cluster_mask]\n",
    "        cluster_docs = np.array(doc_summaries)[cluster_mask]\n",
    "        \n",
    "        centroid = cluster_embeddings.mean(axis=0)\n",
    "        distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "        closest_indices = np.argsort(distances)[:n_per_cluster]\n",
    "        \n",
    "        central_docs[int(cluster_id)] = cluster_docs[closest_indices].tolist()\n",
    "    \n",
    "    return central_docs\n",
    "\n",
    "def get_optimal_k(embeddings, k_range=range(2, 11)):\n",
    "    \"\"\"Previous implementation\"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        scores[k] = score\n",
    "        \n",
    "    optimal_k = max(scores.items(), key=lambda x: x[1])[0]\n",
    "    return optimal_k, {int(k): float(score) for k, score in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information about the discovered clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully connected to MongoDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters: 6\n",
      "\n",
      "Cluster 0:\n",
      "Size: 130 articles\n",
      "Date range: 2024-10-24T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Pravni fakultet: Koleginica nagazila na utičnicu, upala neznatno u pod, komad maltera pao na drugu\n",
      "- Aktivisti kod Starog savskog mosta: Spremni smo na sve, ovo je borba za Beograd, odbranićemo most\n",
      "- Vladimir Pajić: Stari savski most je simbol borbe za normalnu i poštenu Srbiju\n",
      "- U Sarajevu naređena evakuacija zbog mogućeg klizišta, meštani odbili\n",
      "- Inicijativa „Most ostaje“ pozvala na okupljanje i paljenje sveća kod Savskog mosta\n",
      "\n",
      "Cluster 1:\n",
      "Size: 112 articles\n",
      "Date range: 2024-10-24T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Bećirović u SB UN optužio Srbiju da želi da odvoji RS od BiH i pripoji je sebi\n",
      "- DSK: Izveštaj o napretku govori o nesposobnosti vlade na čijem je čelu Kurti\n",
      "- Lopandić: Predstavnici Zapada „presrećni“ što Aleksandar Vučić nije prisustvovao samitu BRIKS-a\n",
      "- Savet bezbednosti UN produžio mandat EUFOR-a u BiH za još godinu dana\n",
      "- Đurđević Stamenkovski poručila Briselu: Vaše kritike su nedobronamerne, Kosovo je deo Srbije\n",
      "\n",
      "Cluster 2:\n",
      "Size: 153 articles\n",
      "Date range: 2024-10-24T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Uhapšen švajcarski državljanin zbog pokazivanja simbola Velike Albanije u Beogradu\n",
      "- Međunarodna poternica za okorelim ubicom u Crnoj Gori: Uključene i policije Srbije i Crne Gore (VIDEO)\n",
      "- Andrej Gnjot na slobodi, napustio Srbiju: Nalazi se na teritoriji EU\n",
      "- Izbušene gume na automobilima srpskih registracija u Kosovskoj Mitrovici\n",
      "- Uhapšen osumnjičeni za pokušaj ubistva u Nišu\n",
      "\n",
      "Cluster 3:\n",
      "Size: 163 articles\n",
      "Date range: 2024-10-24T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- CLS: JKP Gradska čistoća duguje budžetu Beograda 1,55 milijardi dinara\n",
      "- Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "- Od danas veći roditeljski dodatak za decu rođenu od početka godine\n",
      "- Nove cene goriva: Dobra vest za vozače\n",
      "- EPS ugasio 106 blagajni za naplatu električne energije\n",
      "\n",
      "Cluster 4:\n",
      "Size: 229 articles\n",
      "Date range: 2024-10-24T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Pola veka „orlovog“ leta: Piloti sa emocijama o bombarderu J-22, „modernizacija nema smisla“\n",
      "- Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "- Jerinić: U izmenama Krivičnog zakonika tri grupe problematičnih rešenja\n",
      "- Istraživanje Galupa: Građani Srbije najveći jugonostalgičari od svih stanovnika bivše SFRJ\n",
      "- (FOTO) Kostimi Hajdi Klum za Noć veštica su uvek epski\n",
      "\n",
      "Cluster 5:\n",
      "Size: 86 articles\n",
      "Date range: 2024-10-25T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- UKCV: Nema novih žrtava, troje povređenih i dalje u teškom stanju\n",
      "- Arhitekta: Urušavanje dela Železničke stanice znak nebrige i nemara prilikom gradnje\n",
      "- Zvaničnici EU i više država izrazili saučešće građanima Srbije povodom nesreće u Novom Sadu\n",
      "- Pašalić: U najkraćem roku utvrditi odgovornost za tragediju u Novom Sadu\n",
      "- Direktorka KC Vojvodine: Tri osobe u veoma teškom stanju, sve su životno ugrožene\n",
      "\n",
      "Representative documents for Cluster 0:\n",
      "- Miketić poziva na „blokadu upozorenja“ Beograda na vodi – borba za očuvanje Savskog mosta\n",
      "- Aktivisti najavili da ostaju na Starom savskom mostu kako bi sprečili rušenje\n",
      "- Špic tokom celog dana, ali semafor ima radno vreme: Vikendom odmara\n",
      "\n",
      "Representative documents for Cluster 1:\n",
      "- Fon der Lajen u razgovoru s Vučićem: EU će poštovati i čuvati divnu prirodu Srbije\n",
      "- Evroposlanik o litijumu: EU pravi grešku – zbog gladi oko resursa podržava nedemokratske režime\n",
      "- Vučeviću uručen izveštaj EK o Srbiji: Shvatili smo poruke Brisela koje ne čujemo prvi put\n",
      "\n",
      "Representative documents for Cluster 2:\n",
      "- Tužilaštvo predložilo pritvor za muškaraca koji je pucao u ženu i sina na Bežanijskoj kosi\n",
      "- Istraga protiv osumnjičenog da je obljubio devojku\n",
      "- Uhapšene dve osobe: Osumnjičeni da nisu uplaćivali pazar, nego novac zadržavali\n",
      "\n",
      "Representative documents for Cluster 3:\n",
      "- Vlada Srbije usvojila više finansijskih zakona: Od poreza do fondova\n",
      "- Stamenkovski: Od 1. novembra na snazi izmene Zakona o finansijskoj podršci porodicama s decom\n",
      "- Pritisak na prevoznike iz Niša da ne dovoze prosvetare na protest: „Upozorenje iz BIA i MUP“\n",
      "\n",
      "Representative documents for Cluster 4:\n",
      "- Filipović: Povezali smo sajt „Kopaćemo“ s državom i podatke dostavili sudu\n",
      "- Jovanović Ćuta u Loznici: Ovo je potencijalno mesto zločina, ne znamo šta je u glavi psihopate\n",
      "- Na skupštini Loznice nepoželjna opozicija, a živi zid i barikade i za aktiviste i poslanike\n",
      "\n",
      "Representative documents for Cluster 5:\n",
      "- Završena akcija spasavanja: 14 stradalih i troje teško povređenih u urušavanju nadstrešnice na Železničkoj stanici\n",
      "- U Novom Sadu počinje trodnevna žalost, okupljanje u 17 časova\n",
      "- Dačić: Osmoro mrtvih u nesreći u Novom Sadu, ispod ruševina devojka\n"
     ]
    }
   ],
   "source": [
    "# Get MongoDB connection using your existing function\n",
    "client, db, collection = get_mongodb_connection()\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_article_topics(\n",
    "    collection=collection,\n",
    "    min_k=2,\n",
    "    max_k=10\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal number of clusters: {results['optimal_k']}\")\n",
    "\n",
    "# Print cluster statistics\n",
    "for stats in results['cluster_stats']:\n",
    "    print(f\"\\nCluster {stats['cluster_id']}:\")\n",
    "    print(f\"Size: {stats['size']} articles\")\n",
    "    print(f\"Date range: {stats['earliest_date']} to {stats['latest_date']}\")\n",
    "    print(\"Sample titles:\")\n",
    "    for title in stats['sample_titles']:\n",
    "        print(f\"- {title}\")\n",
    "\n",
    "# Print representative documents\n",
    "for cluster_id, docs in results['representative_documents'].items():\n",
    "    print(f\"\\nRepresentative documents for Cluster {cluster_id}:\")\n",
    "    for doc in docs:\n",
    "        print(f\"- {doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming the clusters with Claude API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Claude client\n",
    "anthropic = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Cluster Names:\n",
      "==================================================\n",
      "\n",
      "Cluster 0: Bridge Protests\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Miketić poziva na „blokadu upozorenja“ Beograda na vodi – borba za očuvanje Savskog mosta\n",
      "- Aktivisti najavili da ostaju na Starom savskom mostu kako bi sprečili rušenje\n",
      "\n",
      "Cluster 1: EU-Serbia Relations\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Fon der Lajen u razgovoru s Vučićem: EU će poštovati i čuvati divnu prirodu Srbije\n",
      "- Evroposlanik o litijumu: EU pravi grešku – zbog gladi oko resursa podržava nedemokratske režime\n",
      "\n",
      "Cluster 2: Criminal Investigation\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Tužilaštvo predložilo pritvor za muškaraca koji je pucao u ženu i sina na Bežanijskoj kosi\n",
      "- Istraga protiv osumnjičenog da je obljubio devojku\n",
      "\n",
      "Cluster 3: Government Pressure\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Vlada Srbije usvojila više finansijskih zakona: Od poreza do fondova\n",
      "- Stamenkovski: Od 1. novembra na snazi izmene Zakona o finansijskoj podršci porodicama s decom\n",
      "\n",
      "Cluster 4: Environmental Activism\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Filipović: Povezali smo sajt „Kopaćemo“ s državom i podatke dostavili sudu\n",
      "- Jovanović Ćuta u Loznici: Ovo je potencijalno mesto zločina, ne znamo šta je u glavi psihopate\n",
      "\n",
      "Cluster 5: Tragic Building Collapse\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Završena akcija spasavanja: 14 stradalih i troje teško povređenih u urušavanju nadstrešnice na Železničkoj stanici\n",
      "- U Novom Sadu počinje trodnevna žalost, okupljanje u 17 časova\n"
     ]
    }
   ],
   "source": [
    "def generate_cluster_names(\n",
    "    results: Dict,\n",
    "    anthropic_client: Anthropic,\n",
    "    use_excerpts: bool = False,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: int = 2\n",
    ") -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Generate descriptive names for clusters using Claude API.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing clustering results\n",
    "        anthropic_client: Initialized Anthropic client\n",
    "        use_excerpts: If True, use document excerpts instead of just titles\n",
    "        max_retries: Maximum number of retries for API calls\n",
    "        retry_delay: Delay between retries in seconds\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping cluster IDs to generated names\n",
    "    \"\"\"\n",
    "    cluster_names = {}\n",
    "    \n",
    "    for cluster_id, docs in results['representative_documents'].items():\n",
    "        # Prepare the content for Claude\n",
    "        if use_excerpts:\n",
    "            content = \"\\n\".join([\n",
    "                f\"Document {i+1}:\\nTitle: {doc['title']}\\nExcerpt: {doc['preview']}\"\n",
    "                for i, doc in enumerate(docs)\n",
    "            ])\n",
    "        else:\n",
    "            content = \"\\n\".join([\n",
    "                f\"- {doc['title']}\" for doc in docs\n",
    "            ])\n",
    "        \n",
    "        # Prepare the prompt with stronger emphasis on English output\n",
    "        prompt = f\"\"\"You are an international news categorization expert. The documents below are Serbian news articles.\n",
    "Your task is to provide a short (2-4 words) ENGLISH LANGUAGE descriptive name for this thematic cluster.\n",
    "\n",
    "For example:\n",
    "- If articles are about \"Finansijski zakoni\", name it \"Financial Legislation\"\n",
    "- If articles are about \"Ekološki protesti\", name it \"Environmental Protests\"\n",
    "- If articles are about \"Politička kriza\", name it \"Political Crisis\"\n",
    "\n",
    "Documents from cluster:\n",
    "{content}\n",
    "\n",
    "IMPORTANT: Respond ONLY with the English language cluster name, no Serbian words allowed.\n",
    "Example good responses: \"Economic Reform\", \"Infrastructure Development\", \"Criminal Investigation\"\n",
    "Example bad responses: \"Finansijski zakoni\", \"Ekološki protesti\", \"Politička kriza\" \"\"\"\n",
    "\n",
    "        # Try to get response with retries\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=\"claude-3-opus-20240229\",\n",
    "                    max_tokens=30,\n",
    "                    temperature=0.2,\n",
    "                    messages=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }]\n",
    "                )\n",
    "                \n",
    "                cluster_name = response.content[0].text.strip()\n",
    "                # Additional check to ensure the response is in English\n",
    "                if any(c.lower() in cluster_name.lower() for c in ['č', 'ć', 'š', 'ž', 'đ']):\n",
    "                    raise ValueError(\"Response contains Serbian characters\")\n",
    "                cluster_names[cluster_id] = cluster_name\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Failed to get name for cluster {cluster_id}: {str(e)}\")\n",
    "                    cluster_names[cluster_id] = f\"Cluster {cluster_id}\"\n",
    "                else:\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "    \n",
    "    return cluster_names\n",
    "\n",
    "# Use the function\n",
    "try:\n",
    "    cluster_names = generate_cluster_names(results, anthropic)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nGenerated Cluster Names:\")\n",
    "    print(\"=\" * 50)\n",
    "    for cluster_id, name in cluster_names.items():\n",
    "        print(f\"\\nCluster {cluster_id}: {name}\")\n",
    "        print(\"-\" * 30)\n",
    "        # Print a few sample titles for reference\n",
    "        print(\"Sample titles:\")\n",
    "        for doc in results['representative_documents'][cluster_id][:2]:\n",
    "            print(f\"- {doc['title']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating cluster names: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Bridge Protests',\n",
       " 1: 'EU-Serbia Relations',\n",
       " 2: 'Criminal Investigation',\n",
       " 3: 'Government Pressure',\n",
       " 4: 'Environmental Activism',\n",
       " 5: 'Tragic Building Collapse'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summaries in English with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_news_report(\n",
    "    query: str,\n",
    "    collection,\n",
    "    model: SentenceTransformer,\n",
    "    anthropic_client: Anthropic,\n",
    "    language: str = \"English\",\n",
    "    top_k: int = 10,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: int = 2\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Perform semantic search and generate a news report based on top results.\n",
    "    Translates the query to Serbian before searching and generates report in specified language.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query in English\n",
    "        collection: MongoDB collection\n",
    "        model: Sentence transformer model for embeddings\n",
    "        anthropic_client: Anthropic client\n",
    "        language: Output language for the report\n",
    "        top_k: Number of top articles to consider\n",
    "        max_retries: Maximum number of API retries\n",
    "        retry_delay: Delay between retries in seconds\n",
    "    \n",
    "    Returns:\n",
    "        Generated news report\n",
    "    \"\"\"\n",
    "    # Translate query to Serbian using Claude\n",
    "    translation_prompt = f\"Translate the following {language} text to Serbian latin. Provide only the translation, nothing else: '{query}'\"\n",
    "    \n",
    "    try:\n",
    "        translation_response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            max_tokens=100,\n",
    "            temperature=0,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": translation_prompt\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        serbian_query = translation_response.content[0].text.strip()\n",
    "        print(serbian_query)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Translation failed: {str(e)}\")\n",
    "    \n",
    "    # Generate embedding for Serbian query\n",
    "    query_embedding = model.encode(serbian_query).tolist()\n",
    "    \n",
    "    # Perform vector search\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 100,\n",
    "                \"limit\": top_k\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"title\": 1,\n",
    "                \"content\": 1,\n",
    "                \"date\": 1,\n",
    "                \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = list(collection.aggregate(pipeline))\n",
    "    \n",
    "    # Prepare content for Claude\n",
    "    articles_text = \"\\n\\n\".join([\n",
    "        f\"Article {i+1}:\\nDate: {doc['date']}\\nTitle: {doc['title']}\\nContent: {doc['content'][:500]}...\"\n",
    "        for i, doc in enumerate(results)\n",
    "    ])\n",
    "    \n",
    "    # Create prompt for report generation\n",
    "    prompt = f\"\"\"You are an expert journalist and news analyst. Based on the following {top_k} most relevant Serbian news articles about \"{query}\" (translated to Serbian as \"{serbian_query}\"), \n",
    "create a concise, well-structured news report in {language}. The report should:\n",
    "- Be around 250-300 words\n",
    "- Start with a clear headline\n",
    "- Include key facts, dates, and relevant context\n",
    "- Maintain journalistic neutrality\n",
    "- Focus on the most newsworthy aspects\n",
    "- Include a brief conclusion or outlook\n",
    "Here are the articles:\n",
    "{articles_text}\n",
    "Please write the report in a professional journalistic style.\"\"\"\n",
    "\n",
    "    # Get response from Claude with retries\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = anthropic_client.messages.create(\n",
    "                model=\"claude-3-opus-20240229\",\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            report = response.content[0].text.strip()\n",
    "            return report\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Failed to generate report: {str(e)}\")\n",
    "            time.sleep(retry_delay)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investicije u rudarstvo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b2d26b2e4f4882abeb58eaa41da78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated News Report:\n",
      "================================================================================\n",
      "Headline: Serbia Balances Economic Growth and Environmental Concerns Amid Mining Investments\n",
      "\n",
      "In recent developments, Serbia has been grappling with the complex dynamics of mining investments, particularly in the Jadar region, where the potential for lithium extraction has sparked both economic optimism and environmental concerns.\n",
      "\n",
      "The Serbian government has been actively promoting investments in the mining sector, with the Ministry of Mining and Energy allocating 120 million dinars (approximately €1 million) in subsidies for local governments to install solar panels in public facilities. This initiative aims to support at least 20 projects, covering up to 90% of their total value, as stated by the ministry on October 25, 2024.\n",
      "\n",
      "However, the proposed lithium mining project in Jadar, led by the multinational company Rio Tinto, has faced significant opposition from environmental activists and local communities. Miroslav Aleksić, president of the People's Movement of Serbia (NPS), criticized the government for turning Serbia into a \"mining colony\" while corruption remains the biggest problem in the economy.\n",
      "\n",
      "Despite the concerns, the government has highlighted the potential economic benefits of mining investments. On October 31, 2024, Minister of Mining and Energy Dubravka Đedović Handanović announced that the state-owned power utility Elektroprivreda Srbije (EPS) had achieved a profit of nearly 30 billion dinars (€254 million) in the first nine months of the year, surpassing the planned profit by 30%.\n",
      "\n",
      "The debate surrounding the Jadar lithium mining project has been further complicated by allegations of land acquisition issues and political ties. Activist Nebojša Petković from the \"Ne damo Jadar\" (We Won't Give Jadar) association claimed that Rio Tinto would need to acquire an additional 209 land parcels to proceed with the project.\n",
      "\n",
      "As Serbia navigates the balance between economic growth and environmental sustainability, the government has also emphasized the importance of strategic cooperation with China for the country's economic progress. Marko Čadež, president of the Serbian Chamber of Commerce (PKS), highlighted the significance of connecting ideas and technologies among member countries of the Alliance of Chambers of Commerce of the New International Land-Sea Trade Corridor (ILSTC).\n",
      "\n",
      "Looking ahead, the future of mining investments in Serbia remains uncertain, as the government seeks to address the concerns of environmental activists and local communities while pursuing economic opportunities. The outcome of these deliberations will likely shape Serbia's energy and economic landscape in the years to come.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    # Example query\n",
    "    query = \"Investments in mining\"\n",
    "\n",
    "    report = generate_news_report(\n",
    "        query=query,\n",
    "        collection=collection,\n",
    "        model=model,\n",
    "        anthropic_client=anthropic,\n",
    "        top_k=10,\n",
    "        language=\"English\"\n",
    "\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerated News Report:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(report)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating report: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
