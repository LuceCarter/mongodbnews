{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the articles data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# Third-party\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError, ConnectionFailure\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>artDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Posle nesreće izazvane obrušavanjem nadstrešn...</td>\n",
       "      <td>UKCV: Nema novih žrtava, troje povređenih i da...</td>\n",
       "      <td>2024-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urušavanje nadstrešnice Železničke stanice u ...</td>\n",
       "      <td>Arhitekta: Urušavanje dela Železničke stanice ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Centar za lokalnu samoupravu (CLS) saopštio j...</td>\n",
       "      <td>CLS: JKP Gradska čistoća duguje budžetu Beogra...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zvaničnici Evropske unije i više država, među...</td>\n",
       "      <td>Zvaničnici EU i više država izrazili saučešće ...</td>\n",
       "      <td>2024-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pravni fakultet u Beogradu saopštio je da inf...</td>\n",
       "      <td>Pravni fakultet: Koleginica nagazila na utični...</td>\n",
       "      <td>2024-10-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0   Posle nesreće izazvane obrušavanjem nadstrešn...   \n",
       "1   Urušavanje nadstrešnice Železničke stanice u ...   \n",
       "2   Centar za lokalnu samoupravu (CLS) saopštio j...   \n",
       "3   Zvaničnici Evropske unije i više država, među...   \n",
       "4   Pravni fakultet u Beogradu saopštio je da inf...   \n",
       "\n",
       "                                               title     artDate  \n",
       "0  UKCV: Nema novih žrtava, troje povređenih i da...  2024-11-02  \n",
       "1  Arhitekta: Urušavanje dela Železničke stanice ...  2024-11-01  \n",
       "2  CLS: JKP Gradska čistoća duguje budžetu Beogra...  2024-11-01  \n",
       "3  Zvaničnici EU i više država izrazili saučešće ...  2024-11-01  \n",
       "4  Pravni fakultet: Koleginica nagazila na utični...  2024-10-31  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "articles = pd.read_csv('fa_articles.csv', encoding='utf-8')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Embedić model for Serbian language embeddings\n",
    "# !pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the embeddings for Serbian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('djovak/embedic-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function for concatenating the article's title and content and passing to the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(df: pd.DataFrame, batch_size: int = 32) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate embeddings for concatenated title and content using Embedić.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'title' and 'content' columns\n",
    "        batch_size: Number of texts to process at once\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added 'embedding' column\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df_emb = df.copy()\n",
    "    \n",
    "    # Concatenate title and content\n",
    "    print(\"Concatenating title and content...\")\n",
    "    df_emb['text_for_embedding'] = df_emb['title'] + \" \" + df_emb['content']\n",
    "    \n",
    "    # Generate embeddings in batches\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    # Convert texts to list for batch processing\n",
    "    texts = df_emb['text_for_embedding'].tolist()\n",
    "    \n",
    "    # Process in batches with progress bar\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_text = texts[i:i + batch_size]\n",
    "        batch_embeddings = model.encode(batch_text)\n",
    "        embeddings.extend(batch_embeddings.tolist())\n",
    "    \n",
    "    # Add embeddings to dataframe\n",
    "    df_emb['embedding'] = embeddings\n",
    "    \n",
    "    # Remove temporary concatenated text column\n",
    "    df_emb = df_emb.drop('text_for_embedding', axis=1)\n",
    "    \n",
    "    print(f\"Generated embeddings for {len(df_emb)} articles\")\n",
    "    print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "    \n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating title and content...\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec3793ee1d841bb90e5c9d1d2fe6ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 20 articles\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "df_with_embeddings = generate_embeddings(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the generated embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame shape: (20, 4)\n",
      "\n",
      "Columns: ['content', 'title', 'artDate', 'embedding']\n",
      "\n",
      "Sample embedding (first 5 dimensions):\n",
      "[0.036100856959819794, -0.03139951825141907, -0.02158968150615692, -0.02952212281525135, 0.06143483147025108]\n",
      "\n",
      "All embeddings have same dimension: True\n",
      "Embedding dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "# Preview the results\n",
    "print(\"\\nDataFrame shape:\", df_with_embeddings.shape)\n",
    "print(\"\\nColumns:\", df_with_embeddings.columns.tolist())\n",
    "\n",
    "# Sample embedding vector (first 5 dimensions)\n",
    "print(\"\\nSample embedding (first 5 dimensions):\")\n",
    "print(df_with_embeddings['embedding'].iloc[0][:5])\n",
    "\n",
    "# Verify embedding dimensions are consistent\n",
    "embedding_lengths = df_with_embeddings['embedding'].apply(len)\n",
    "print(\"\\nAll embeddings have same dimension:\", embedding_lengths.nunique() == 1)\n",
    "print(\"Embedding dimension:\", embedding_lengths.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_mongodb(df: pd.DataFrame) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame rows to MongoDB documents.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with embeddings\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries ready for MongoDB insertion\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        document = {           \n",
    "            'title': row['title'],\n",
    "            'content': row['content'],\n",
    "            'date': row['artDate'],  # Assuming you have a date column\n",
    "            'embedding': row['embedding'],\n",
    "            'metadata': {\n",
    "                'embedding_model': 'djovak/embedic-large',\n",
    "                'created_at': datetime.now(),\n",
    "                'last_updated': datetime.now()\n",
    "            }\n",
    "        }\n",
    "        documents.append(document)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67400fee6579499e9ae299d0d859e5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared 20 documents for MongoDB insertion\n",
      "\n",
      "Sample document structure (excluding embedding vector):\n",
      "{\n",
      "  \"title\": \"UKCV: Nema novih \\u017ertava, troje povre\\u0111enih i dalje u te\\u0161kom stanju\",\n",
      "  \"content\": \" Posle nesre\\u0107e izazvane obru\\u0161avanjem nadstre\\u0161nice na \\u017delezni\\u010dkoj stanici u Novom Sadu, novih \\u017ertava nema, a troje povre\\u0111enih je u te\\u0161kom op\\u0161tem stanju, potvr\\u0111eno je za Tanjug u Univerzitetskom klini\\u010dkom centru Vojvodine (UKCV). \\u201eTroje povre\\u0111enih koji su ju\\u010de primljeni u UKCV i dalje su u te\\u0161kom stanju, na intenzivnoj nezi\\u201c, re\\u010deno je iz Pres-slu\\u017ebe Klini\\u010dkog centra za Tanjug. Portparolka De\\u010dje bolnice Andrea \\u0110ureti\\u0107 rekla je da ni sino\\u0107 u tu bolnicu nisu primljene dve devoj\\u010dice. Povezane vesti U Srbiji danas Dan \\u017ealosti, u Novom Sadu trodnevna Vesti 08:16 27 Vesti 08:16 27 Zavr\\u0161ena akcija spasavanja: 14 stradalih i troje te\\u0161ko povre\\u0111enih u uru\\u0161avanju nadstre\\u0161nice na \\u017delezni\\u010dkoj stanici Vesti 23:31 602 Vesti 23:31 602 \\u201ePovodom informacije koju prenose mediji da su dve devoj\\u010dice preminule, mi ne znamo da li su devoj\\u010dice bile na \\u017delezni\\u010dkoj stanici i mo\\u017eda su me\\u0111u 14 poginulih, ali u bolnicu nisu primljene i nema novih \\u017ertvi\\u201c, re\\u010deno je iz De\\u010dje bolnice u Novom Sadu. Za dalje informacije za javnost, nadle\\u017ena je policija. Mediji prenose da su tokom no\\u0107i dve devoj\\u010dice preminule u Urgentnom centru u Novom Sadu. Prema poslednjim zvani\\u010dnim podacima, \\u010detrnaestoro ljudi je ju\\u010de poginulo, a troje je povre\\u0111eno u nesre\\u0107i izazvanoj uru\\u0161avanjem nadstre\\u0161nice na staroj zgradi \\u017delezni\\u010dke stanice u Novom Sadu. Vlada Srbije proglasila je 2. novembar za Dan \\u017ealosti zbog ove tragedije, dok je u Novom Sadu progla\\u0161ena trodnevna \\u017ealost.\",\n",
      "  \"date\": \"2024-11-02\",\n",
      "  \"embedding\": \"<embedding vector with 1024 dimensions>\",\n",
      "  \"metadata\": {\n",
      "    \"embedding_model\": \"djovak/embedic-large\",\n",
      "    \"created_at\": \"2024-11-26 21:21:26.571276\",\n",
      "    \"last_updated\": \"2024-11-26 21:21:26.571276\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to MongoDB documents\n",
    "mongodb_documents = prepare_for_mongodb(df_with_embeddings)\n",
    "print(f\"\\nPrepared {len(mongodb_documents)} documents for MongoDB insertion\")\n",
    "print(\"\\nSample document structure (excluding embedding vector):\")\n",
    "sample_doc = mongodb_documents[0].copy()\n",
    "sample_doc['embedding'] = f\"<embedding vector with {len(sample_doc['embedding'])} dimensions>\"\n",
    "print(json.dumps(sample_doc, default=str, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data into the MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# MongoDB connection setup\n",
    "MONGODB_URI = os.getenv(\"MONGODB_URI\")\n",
    "DB_NAME = os.getenv(\"DB_NAME_1\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "if not all([MONGODB_URI, DB_NAME, COLLECTION_NAME]):\n",
    "    raise ValueError(\"Missing required environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully connected to MongoDB\n"
     ]
    }
   ],
   "source": [
    "def get_mongodb_connection():\n",
    "    \"\"\"\n",
    "    Create and return MongoDB client, database and collection objects.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (MongoClient, Database, Collection)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = MongoClient(MONGODB_URI)\n",
    "        # Test connection\n",
    "        client.admin.command('ping')\n",
    "        logger.info(\"Successfully connected to MongoDB\")\n",
    "        \n",
    "        db = client[DB_NAME]\n",
    "        collection = db[COLLECTION_NAME]\n",
    "        return client, db, collection\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to connect to MongoDB. Error: {str(e)}\")\n",
    "        raise ConnectionFailure(f\"MongoDB connection failed: {str(e)}\")\n",
    "\n",
    "client, db, collection = get_mongodb_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for inserting data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_documents_to_mongodb(documents: List[Dict], \n",
    "                              batch_size: int = 1000) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Insert documents into MongoDB in batches.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of documents to insert\n",
    "        batch_size: Number of documents to insert in each batch\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (successful insertions, failed insertions)\n",
    "    \"\"\"\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    \n",
    "    print(f\"Starting insertion of {len(documents)} documents...\")\n",
    "    \n",
    "    for i in tqdm(range(0, len(documents), batch_size)):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        try:\n",
    "            # Insert batch with ordered=False for better performance\n",
    "            result = collection.insert_many(batch, ordered=False)\n",
    "            successful += len(result.inserted_ids)\n",
    "        except BulkWriteError as e:\n",
    "            # Handle partial failures in batch\n",
    "            successful += e.details['nInserted']\n",
    "            failed += len(batch) - e.details['nInserted']\n",
    "            print(f\"Batch {i//batch_size + 1} had {e.details['nInserted']} successful and \"\n",
    "                  f\"{len(batch) - e.details['nInserted']} failed insertions\")\n",
    "    \n",
    "    return successful, failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearing the collection and inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting insertion of 20 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a2c496e13d437b8de70dc593f84693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insertion complete:\n",
      "Successfully inserted: 20 documents\n",
      "Failed insertions: 0 documents\n"
     ]
    }
   ],
   "source": [
    "collection.delete_many({})\n",
    "# Insert documents\n",
    "successful, failed = insert_documents_to_mongodb(mongodb_documents)\n",
    "print(f\"\\nInsertion complete:\")\n",
    "print(f\"Successfully inserted: {successful} documents\")\n",
    "print(f\"Failed insertions: {failed} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'numDimensions': 1024,\n",
       "   'path': 'embedding',\n",
       "   'similarity': 'cosine',\n",
       "   'type': 'vector'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"numDimensions\": 1024,\n",
    "      \"path\": \"embedding\",\n",
    "      \"similarity\": \"cosine\",\n",
    "      \"type\": \"vector\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_index(\n",
    "    connection_string: str,\n",
    "    database_name: str,\n",
    "    collection_name: str,\n",
    "    index_name: str = \"vector_index\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a vector search index in MongoDB using PyMongo.\n",
    "    \n",
    "    Args:\n",
    "        connection_string: MongoDB connection string\n",
    "        database_name: Name of the database\n",
    "        collection_name: Name of the collection\n",
    "        index_name: Name of the vector index\n",
    "    \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    client = client\n",
    "    \n",
    "    # Get database and collection\n",
    "    db = db\n",
    "    collection = collection\n",
    "    \n",
    "    # Define the index configuration\n",
    "    index_config = {\n",
    "        \"name\": index_name,\n",
    "        \"definition\": {\n",
    "            \"fields\": [\n",
    "                {\n",
    "                    \"numDimensions\": 1024,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"similarity\": \"cosine\",\n",
    "                    \"type\": \"vector\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Create the vector search index\n",
    "        collection.create_search_index(index_config)\n",
    "        print(f\"Successfully created vector index '{index_name}'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector index: {str(e)}\")        \n",
    "    finally:\n",
    "        client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection Information:\n",
      "Total documents: 20\n",
      "Indexes: {'_id_': {'v': 2, 'key': [('_id', 1)]}, 'articleDate_1': {'v': 2, 'key': [('articleDate', 1)]}, 'title_text_content_text': {'v': 2, 'key': [('_fts', 'text'), ('_ftsx', 1)], 'weights': SON([('content', 1), ('title', 1)]), 'default_language': 'english', 'language_override': 'language', 'textIndexVersion': 3}}\n"
     ]
    }
   ],
   "source": [
    "# Create standard indexes for better query performance\n",
    "\n",
    "#collection.create_index(\"articleDate\")\n",
    "#collection.create_index([(\"title\", \"text\"), (\"content\", \"text\")])\n",
    "\n",
    "# Verify the setup\n",
    "print(\"\\nCollection Information:\")\n",
    "print(f\"Total documents: {collection.count_documents({})}\")\n",
    "print(f\"Indexes: {collection.index_information()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search with MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c0ac8171da4e8daacac52fc5b4b5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Novi Sad\n",
      "================================================================================\n",
      "\n",
      "1. Vučević: Insistiraćemo da se pronađu odgovorni za nesreću u Novom Sadu\n",
      "Score: 0.836\n",
      "\n",
      "Excerpt: Ovo je jedan od najtežih dana u posleratnoj istoriji Novog Sada i užasna tragedija, rekao je premijer Srbije Miloš Vučević. „Ovo je jedan od najtežih dana u posleratnoj istoriji Novog Sada i užasna tr...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Pašalić: U najkraćem roku utvrditi odgovornost za tragediju u Novom Sadu\n",
      "Score: 0.834\n",
      "\n",
      "Excerpt:  Zaštitnik građana Zoran Pašalić pozvao je nadležne da preduzmu sve potrebne mere da bi se u najkraćem roku utvrdila odgovornost za pogibiju 14 ljudi na koje se danas srušila betonska nadstrešnica Žel...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Arhitekta: Urušavanje dela Železničke stanice znak nebrige i nemara prilikom gradnje\n",
      "Score: 0.833\n",
      "\n",
      "Excerpt:  Urušavanje nadstrešnice Železničke stanice u Novom Sadu prilikom čega je najmanje jedna osoba stradala dok je više njih povređeno, znak je nebrige i nemara prilikom gradnje, kaže za  arhitekta Slobod...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Direktorka KC Vojvodine: Tri osobe u veoma teškom stanju, sve su životno ugrožene\n",
      "Score: 0.829\n",
      "\n",
      "Excerpt:  Direktorka Kliničkog centra Vojvodine Vesna Turkulov rekla je da su tri osobe koje su izvučene iz ruševina nakon što se obrušila nadstrešnica Železničke stanice u Novom Sadu u veoma teškom stanju, od...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Zvaničnici EU i više država izrazili saučešće građanima Srbije povodom nesreće u Novom Sadu\n",
      "Score: 0.829\n",
      "\n",
      "Excerpt:  Zvaničnici Evropske unije i više država, među kojima su i susedne, uputili su saučešće građanima Srbije povodom pogibije ljudi usled pada betonske nadstrešnice na Železničkoj stanici u Novom Sadu. Ko...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. UKCV: Nema novih žrtava, troje povređenih i dalje u teškom stanju\n",
      "Score: 0.824\n",
      "\n",
      "Excerpt:  Posle nesreće izazvane obrušavanjem nadstrešnice na Železničkoj stanici u Novom Sadu, novih žrtava nema, a troje povređenih je u teškom opštem stanju, potvrđeno je za Tanjug u Univerzitetskom kliničk...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd5569579914f899333340be5eaae49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Lithium\n",
      "================================================================================\n",
      "\n",
      "1. Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "Score: 0.788\n",
      "\n",
      "Excerpt: /yy_Apartment Ministarstvo privrede objavilo je javni poziv za prikupljanje pisama o zainteresovanosti za učestvovanje u postupku privatizacije saobraćajnog preduzeća Lastra iz Lazarevca, piše portal ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Pravni fakultet: Koleginica nagazila na utičnicu, upala neznatno u pod, komad maltera pao na drugu\n",
      "Score: 0.782\n",
      "\n",
      "Excerpt:  Pravni fakultet u Beogradu saopštio je da informacija da je jedna \"studentkinja propala kroz plafon čitaonice\", ne odgovara istini. (FOTO) Devojka propala kroz pod čitaonice na Pravnom fakultetu u Be...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. U Sarajevu naređena evakuacija zbog mogućeg klizišta, meštani odbili\n",
      "Score: 0.780\n",
      "\n",
      "Excerpt:  Sarajevo Direktor Civilne zaštite Kantona Sarajevo Dženan Brkanić izjavio je da se klizište na Trebeviću, koje preti sarajevskom naselju Širokača, ne može brzo sanirati za šta je potrebna i saglasnos...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Pola veka „orlovog“ leta: Piloti sa emocijama o bombarderu J-22, „modernizacija nema smisla“\n",
      "Score: 0.771\n",
      "\n",
      "Excerpt: youtube/printscreen/ Vojska Srbije — zvanični kanal Jurišnik-bombarder \"orao\" (J-22), zajednički proizvod vojnih industrija tadašnje SFRJ i Rumunije, svoj prvi let je imao na današnji dan pre 50 godin...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Arhitekta: Urušavanje dela Železničke stanice znak nebrige i nemara prilikom gradnje\n",
      "Score: 0.767\n",
      "\n",
      "Excerpt:  Urušavanje nadstrešnice Železničke stanice u Novom Sadu prilikom čega je najmanje jedna osoba stradala dok je više njih povređeno, znak je nebrige i nemara prilikom gradnje, kaže za  arhitekta Slobod...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "Score: 0.765\n",
      "\n",
      "Excerpt: Google Povodom najčešćih predloga, primedaba i sugestija na izmene i dopune Krivičnog zakonika koji su podneti Ministarstvu pravde u toku javne rasprave, ministarstvo je danas saopštilo da će pojedine...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b576638c3b45fc83fc1615a2ec27b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Freedom politics\n",
      "================================================================================\n",
      "\n",
      "1. Jerinić: U izmenama Krivičnog zakonika tri grupe problematičnih rešenja\n",
      "Score: 0.789\n",
      "\n",
      "Excerpt: Poslanica Zeleno-levog fronta Jelena Jerinić izjavila je da u izmenama Krivičnog zakonika i Zakonika o krivičnom postupku postoje tri grupe prolematičnih rešenja, a to su populističko pooštravanje kaz...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Vladimir Pajić: Stari savski most je simbol borbe za normalnu i poštenu Srbiju\n",
      "Score: 0.786\n",
      "\n",
      "Excerpt:  Predstavnik Pokreta slobodnih građana (PSG) Vladimir Pajić ocenio je da je Stari savski most u Beogradu simbol borbe za normalnu, poštenu, požrtvovanu i slobodnu Srbiju i grad \"koji postoji zbog ljud...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "Score: 0.781\n",
      "\n",
      "Excerpt: /yy_Apartment Ministarstvo privrede objavilo je javni poziv za prikupljanje pisama o zainteresovanosti za učestvovanje u postupku privatizacije saobraćajnog preduzeća Lastra iz Lazarevca, piše portal ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "Score: 0.778\n",
      "\n",
      "Excerpt: Google Povodom najčešćih predloga, primedaba i sugestija na izmene i dopune Krivičnog zakonika koji su podneti Ministarstvu pravde u toku javne rasprave, ministarstvo je danas saopštilo da će pojedine...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Uhapšen švajcarski državljanin zbog pokazivanja simbola Velike Albanije u Beogradu\n",
      "Score: 0.775\n",
      "\n",
      "Excerpt:  Potpredsednik Vlade i ministar unutrašnjih poslova Ivica Dačić izjavio je da je policija u Beogradu uhapsila državljanina Švajcarske, koji je na uglu ulica Takovske i Trga Nikole Pašića pokazivalo si...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "6. Aktivisti kod Starog savskog mosta: Spremni smo na sve, ovo je borba za Beograd, odbranićemo most\n",
      "Score: 0.774\n",
      "\n",
      "Excerpt:  Grupa aktivista koja se protivi rušenju Starog savskog mosta, a prenoćila je nedaleko od parka kod bivše Autobuske stanice, za večeras najavljuje nove akcije i poručuje da je ovo borba za Beograd i d...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_search(collection, query: str, k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform semantic search using Embedić vector similarity.\n",
    "    \n",
    "    Args:\n",
    "        collection: MongoDB collection\n",
    "        query: Search query text\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of matching documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for query using Embedić\n",
    "        query_embedding = model.encode(query).tolist()\n",
    "        \n",
    "        # Perform vector search\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"vector_index\",\n",
    "                    \"queryVector\": query_embedding,\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"numCandidates\": 100,\n",
    "                    \"limit\": k\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"title\": 1,\n",
    "                    \"content\": 1,\n",
    "                    \"date\": 1,             \n",
    "                    \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        results = list(collection.aggregate(pipeline))\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def display_search_results(query: str, results: List[Dict]):\n",
    "    \"\"\"\n",
    "    Display search results in a readable format\n",
    "    \"\"\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. {doc['title']}\")\n",
    "        print(f\"Score: {doc['score']:.3f}\")\n",
    "        print(f\"\\nExcerpt: {doc['content'][:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Test the search\n",
    "queries = [\n",
    "    \"Novi Sad\",\"Lithium\", \"Freedom politics\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results = semantic_search(collection, query, k=6)\n",
    "    display_search_results(query, results)\n",
    "    print(\"\\n\" + \"=\" * 100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means clustering of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\desktop\\correspondent\\venv\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\desktop\\correspondent\\venv\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\desktop\\correspondent\\venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\desktop\\correspondent\\venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\desktop\\correspondent\\venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def analyze_article_topics(\n",
    "    collection,\n",
    "    min_k: int = 2,\n",
    "    max_k: int = 10,\n",
    "    embedding_field: str = \"embedding\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze topics in articles stored in MongoDB using their embeddings\n",
    "    \n",
    "    Args:\n",
    "        collection: MongoDB collection object\n",
    "        min_k: Minimum number of clusters to try\n",
    "        max_k: Maximum number of clusters to try\n",
    "        embedding_field: Name of the field containing embeddings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    # Fetch all documents\n",
    "    documents = list(collection.find(\n",
    "        {embedding_field: {\"$exists\": True}},\n",
    "        {\"title\": 1, \"content\": 1, \"date\": 1, embedding_field: 1}\n",
    "    ))\n",
    "    \n",
    "    if not documents:\n",
    "        raise ValueError(\"No documents found with embeddings\")\n",
    "    \n",
    "    # Extract embeddings and create a mapping of texts\n",
    "    embeddings = np.array([doc[embedding_field] for doc in documents])\n",
    "    \n",
    "    # Create document summaries for easier reference\n",
    "    doc_summaries = [\n",
    "        {\n",
    "            \"id\": str(doc[\"_id\"]),\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"date\": doc[\"date\"],\n",
    "            \"preview\": doc[\"content\"][:200] + \"...\"  # First 200 chars\n",
    "        }\n",
    "        for doc in documents\n",
    "    ]\n",
    "    \n",
    "    # Find optimal number of clusters\n",
    "    optimal_k, scores = get_optimal_k(embeddings, k_range=range(min_k, max_k + 1))\n",
    "    \n",
    "    # Perform clustering with optimal k\n",
    "    labels, kmeans = cluster_documents(embeddings, k=optimal_k)\n",
    "    \n",
    "    # Get representative documents for each cluster\n",
    "    central_docs = find_central_documents(embeddings, labels, doc_summaries)\n",
    "    \n",
    "    # Calculate cluster statistics\n",
    "    cluster_stats = calculate_cluster_stats(doc_summaries, labels)\n",
    "    \n",
    "    # Organize results\n",
    "    results = {\n",
    "        \"optimal_k\": optimal_k,\n",
    "        \"silhouette_scores\": scores,\n",
    "        \"cluster_assignments\": [int(label) for label in labels],\n",
    "        \"cluster_stats\": cluster_stats,\n",
    "        \"representative_documents\": central_docs,\n",
    "        \"document_mapping\": {\n",
    "            str(doc[\"_id\"]): {\n",
    "                \"cluster\": int(label),\n",
    "                \"title\": doc[\"title\"],\n",
    "                \"date\": doc[\"date\"].isoformat() if isinstance(doc[\"date\"], datetime) else doc[\"date\"]\n",
    "            }\n",
    "            for doc, label in zip(documents, labels)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Keep the helper functions from before\n",
    "def calculate_cluster_stats(doc_summaries: List[Dict], labels: np.ndarray) -> List[Dict]:\n",
    "    \n",
    "    cluster_stats = []\n",
    "    unique_labels = sorted(set(labels))\n",
    "    \n",
    "    for cluster_id in unique_labels:\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_docs = [doc for doc, is_in_cluster in zip(doc_summaries, cluster_mask) if is_in_cluster]\n",
    "        \n",
    "        dates = [\n",
    "            datetime.fromisoformat(doc[\"date\"]) if isinstance(doc[\"date\"], str) \n",
    "            else doc[\"date\"] \n",
    "            for doc in cluster_docs\n",
    "        ]\n",
    "        \n",
    "        stats = {\n",
    "            \"cluster_id\": int(cluster_id),\n",
    "            \"size\": int(sum(cluster_mask)),\n",
    "            \"earliest_date\": min(dates).isoformat(),\n",
    "            \"latest_date\": max(dates).isoformat(),\n",
    "            \"date_range_days\": (max(dates) - min(dates)).days,\n",
    "            \"sample_titles\": [doc[\"title\"] for doc in cluster_docs[:5]]\n",
    "        }\n",
    "        cluster_stats.append(stats)\n",
    "    \n",
    "    return cluster_stats\n",
    "\n",
    "def cluster_documents(embeddings, k, random_state=42):\n",
    "   \n",
    "    kmeans = KMeans(n_clusters=k, random_state=random_state)\n",
    "    labels = kmeans.fit_predict(embeddings)\n",
    "    return labels, kmeans\n",
    "\n",
    "def find_central_documents(embeddings, labels, doc_summaries, n_per_cluster=3):\n",
    "   \n",
    "    central_docs = {}\n",
    "    \n",
    "    for cluster_id in np.unique(labels):\n",
    "        cluster_mask = labels == cluster_id\n",
    "        cluster_embeddings = embeddings[cluster_mask]\n",
    "        cluster_docs = np.array(doc_summaries)[cluster_mask]\n",
    "        \n",
    "        centroid = cluster_embeddings.mean(axis=0)\n",
    "        distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "        closest_indices = np.argsort(distances)[:n_per_cluster]\n",
    "        \n",
    "        central_docs[int(cluster_id)] = cluster_docs[closest_indices].tolist()\n",
    "    \n",
    "    return central_docs\n",
    "\n",
    "def get_optimal_k(embeddings, k_range=range(2, 11)):\n",
    "    \"\"\"Previous implementation\"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        scores[k] = score\n",
    "        \n",
    "    optimal_k = max(scores.items(), key=lambda x: x[1])[0]\n",
    "    return optimal_k, {int(k): float(score) for k, score in scores.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information about the discovered clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully connected to MongoDB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters: 8\n",
      "\n",
      "Cluster 0:\n",
      "Size: 6 articles\n",
      "Date range: 2024-11-01T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- UKCV: Nema novih žrtava, troje povređenih i dalje u teškom stanju\n",
      "- Arhitekta: Urušavanje dela Železničke stanice znak nebrige i nemara prilikom gradnje\n",
      "- Zvaničnici EU i više država izrazili saučešće građanima Srbije povodom nesreće u Novom Sadu\n",
      "- Pašalić: U najkraćem roku utvrditi odgovornost za tragediju u Novom Sadu\n",
      "- Direktorka KC Vojvodine: Tri osobe u veoma teškom stanju, sve su životno ugrožene\n",
      "\n",
      "Cluster 1:\n",
      "Size: 3 articles\n",
      "Date range: 2024-10-31T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Uhapšen švajcarski državljanin zbog pokazivanja simbola Velike Albanije u Beogradu\n",
      "- U Sarajevu naređena evakuacija zbog mogućeg klizišta, meštani odbili\n",
      "- Međunarodna poternica za okorelim ubicom u Crnoj Gori: Uključene i policije Srbije i Crne Gore (VIDEO)\n",
      "\n",
      "Cluster 2:\n",
      "Size: 2 articles\n",
      "Date range: 2024-10-31T00:00:00 to 2024-10-31T00:00:00\n",
      "Sample titles:\n",
      "- Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "- Jerinić: U izmenama Krivičnog zakonika tri grupe problematičnih rešenja\n",
      "\n",
      "Cluster 3:\n",
      "Size: 3 articles\n",
      "Date range: 2024-10-31T00:00:00 to 2024-11-02T00:00:00\n",
      "Sample titles:\n",
      "- Aktivisti kod Starog savskog mosta: Spremni smo na sve, ovo je borba za Beograd, odbranićemo most\n",
      "- Vladimir Pajić: Stari savski most je simbol borbe za normalnu i poštenu Srbiju\n",
      "- Inicijativa „Most ostaje“ pozvala na okupljanje i paljenje sveća kod Savskog mosta\n",
      "\n",
      "Cluster 4:\n",
      "Size: 1 articles\n",
      "Date range: 2024-10-31T00:00:00 to 2024-10-31T00:00:00\n",
      "Sample titles:\n",
      "- Pravni fakultet: Koleginica nagazila na utičnicu, upala neznatno u pod, komad maltera pao na drugu\n",
      "\n",
      "Cluster 5:\n",
      "Size: 2 articles\n",
      "Date range: 2024-10-31T00:00:00 to 2024-10-31T00:00:00\n",
      "Sample titles:\n",
      "- Pola veka „orlovog“ leta: Piloti sa emocijama o bombarderu J-22, „modernizacija nema smisla“\n",
      "- Istraživanje Galupa: Građani Srbije najveći jugonostalgičari od svih stanovnika bivše SFRJ\n",
      "\n",
      "Cluster 6:\n",
      "Size: 2 articles\n",
      "Date range: 2024-11-01T00:00:00 to 2024-11-01T00:00:00\n",
      "Sample titles:\n",
      "- CLS: JKP Gradska čistoća duguje budžetu Beograda 1,55 milijardi dinara\n",
      "- Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "\n",
      "Cluster 7:\n",
      "Size: 1 articles\n",
      "Date range: 2024-11-01T00:00:00 to 2024-11-01T00:00:00\n",
      "Sample titles:\n",
      "- Ministar policije: Raspisan konkurs za 1.500 policajaca, najviše fale u Beogradu i Vojvodini\n",
      "\n",
      "Representative documents for Cluster 0:\n",
      "- Pašalić: U najkraćem roku utvrditi odgovornost za tragediju u Novom Sadu\n",
      "- UKCV: Nema novih žrtava, troje povređenih i dalje u teškom stanju\n",
      "- Direktorka KC Vojvodine: Tri osobe u veoma teškom stanju, sve su životno ugrožene\n",
      "\n",
      "Representative documents for Cluster 1:\n",
      "- Međunarodna poternica za okorelim ubicom u Crnoj Gori: Uključene i policije Srbije i Crne Gore (VIDEO)\n",
      "- U Sarajevu naređena evakuacija zbog mogućeg klizišta, meštani odbili\n",
      "- Uhapšen švajcarski državljanin zbog pokazivanja simbola Velike Albanije u Beogradu\n",
      "\n",
      "Representative documents for Cluster 2:\n",
      "- Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "- Jerinić: U izmenama Krivičnog zakonika tri grupe problematičnih rešenja\n",
      "\n",
      "Representative documents for Cluster 3:\n",
      "- Aktivisti kod Starog savskog mosta: Spremni smo na sve, ovo je borba za Beograd, odbranićemo most\n",
      "- Vladimir Pajić: Stari savski most je simbol borbe za normalnu i poštenu Srbiju\n",
      "- Inicijativa „Most ostaje“ pozvala na okupljanje i paljenje sveća kod Savskog mosta\n",
      "\n",
      "Representative documents for Cluster 4:\n",
      "- Pravni fakultet: Koleginica nagazila na utičnicu, upala neznatno u pod, komad maltera pao na drugu\n",
      "\n",
      "Representative documents for Cluster 5:\n",
      "- Pola veka „orlovog“ leta: Piloti sa emocijama o bombarderu J-22, „modernizacija nema smisla“\n",
      "- Istraživanje Galupa: Građani Srbije najveći jugonostalgičari od svih stanovnika bivše SFRJ\n",
      "\n",
      "Representative documents for Cluster 6:\n",
      "- CLS: JKP Gradska čistoća duguje budžetu Beograda 1,55 milijardi dinara\n",
      "- Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "\n",
      "Representative documents for Cluster 7:\n",
      "- Ministar policije: Raspisan konkurs za 1.500 policajaca, najviše fale u Beogradu i Vojvodini\n"
     ]
    }
   ],
   "source": [
    "# Get MongoDB connection using your existing function\n",
    "client, db, collection = get_mongodb_connection()\n",
    "\n",
    "# Run the analysis\n",
    "results = analyze_article_topics(\n",
    "    collection=collection,\n",
    "    min_k=2,\n",
    "    max_k=10\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Optimal number of clusters: {results['optimal_k']}\")\n",
    "\n",
    "# Print cluster statistics\n",
    "for stats in results['cluster_stats']:\n",
    "    print(f\"\\nCluster {stats['cluster_id']}:\")\n",
    "    print(f\"Size: {stats['size']} articles\")\n",
    "    print(f\"Date range: {stats['earliest_date']} to {stats['latest_date']}\")\n",
    "    print(\"Sample titles:\")\n",
    "    for title in stats['sample_titles']:\n",
    "        print(f\"- {title}\")\n",
    "\n",
    "# Print representative documents\n",
    "for cluster_id, docs in results['representative_documents'].items():\n",
    "    print(f\"\\nRepresentative documents for Cluster {cluster_id}:\")\n",
    "    for doc in docs:\n",
    "        print(f\"- {doc['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming the clusters with Claude API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Claude client\n",
    "anthropic = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Cluster Names:\n",
      "==================================================\n",
      "\n",
      "Cluster 0: Hospital Tragedy\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Pašalić: U najkraćem roku utvrditi odgovornost za tragediju u Novom Sadu\n",
      "- UKCV: Nema novih žrtava, troje povređenih i dalje u teškom stanju\n",
      "\n",
      "Cluster 1: Crime and Security\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Međunarodna poternica za okorelim ubicom u Crnoj Gori: Uključene i policije Srbije i Crne Gore (VIDEO)\n",
      "- U Sarajevu naređena evakuacija zbog mogućeg klizišta, meštani odbili\n",
      "\n",
      "Cluster 2: Criminal Code Amendments\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Ministarstvo pravde će precizirati članove Krivičnog zakonika na koje su stigle primedbe\n",
      "- Jerinić: U izmenama Krivičnog zakonika tri grupe problematičnih rešenja\n",
      "\n",
      "Cluster 3: Savski Bridge Protests\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Aktivisti kod Starog savskog mosta: Spremni smo na sve, ovo je borba za Beograd, odbranićemo most\n",
      "- Vladimir Pajić: Stari savski most je simbol borbe za normalnu i poštenu Srbiju\n",
      "\n",
      "Cluster 4: Workplace Accident\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Pravni fakultet: Koleginica nagazila na utičnicu, upala neznatno u pod, komad maltera pao na drugu\n",
      "\n",
      "Cluster 5: Yugoslav Nostalgia\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Pola veka „orlovog“ leta: Piloti sa emocijama o bombarderu J-22, „modernizacija nema smisla“\n",
      "- Istraživanje Galupa: Građani Srbije najveći jugonostalgičari od svih stanovnika bivše SFRJ\n",
      "\n",
      "Cluster 6: Public Enterprises\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- CLS: JKP Gradska čistoća duguje budžetu Beograda 1,55 milijardi dinara\n",
      "- Država traži kupce za svoj kapital u saobraćajnom preduzeću Lastra, poziva ih da predlože cenu\n",
      "\n",
      "Cluster 7: Police Recruitment\n",
      "------------------------------\n",
      "Sample titles:\n",
      "- Ministar policije: Raspisan konkurs za 1.500 policajaca, najviše fale u Beogradu i Vojvodini\n"
     ]
    }
   ],
   "source": [
    "def generate_cluster_names(\n",
    "    results: Dict,\n",
    "    anthropic_client: Anthropic,\n",
    "    use_excerpts: bool = False,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: int = 2\n",
    ") -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Generate descriptive names for clusters using Claude API.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing clustering results\n",
    "        anthropic_client: Initialized Anthropic client\n",
    "        use_excerpts: If True, use document excerpts instead of just titles\n",
    "        max_retries: Maximum number of retries for API calls\n",
    "        retry_delay: Delay between retries in seconds\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping cluster IDs to generated names\n",
    "    \"\"\"\n",
    "    cluster_names = {}\n",
    "    \n",
    "    for cluster_id, docs in results['representative_documents'].items():\n",
    "        # Prepare the content for Claude\n",
    "        if use_excerpts:\n",
    "            content = \"\\n\".join([\n",
    "                f\"Document {i+1}:\\nTitle: {doc['title']}\\nExcerpt: {doc['preview']}\"\n",
    "                for i, doc in enumerate(docs)\n",
    "            ])\n",
    "        else:\n",
    "            content = \"\\n\".join([\n",
    "                f\"- {doc['title']}\" for doc in docs\n",
    "            ])\n",
    "        \n",
    "        # Prepare the prompt with stronger emphasis on English output\n",
    "        prompt = f\"\"\"You are an international news categorization expert. The documents below are Serbian news articles.\n",
    "Your task is to provide a short (2-4 words) ENGLISH LANGUAGE descriptive name for this thematic cluster.\n",
    "\n",
    "For example:\n",
    "- If articles are about \"Finansijski zakoni\", name it \"Financial Legislation\"\n",
    "- If articles are about \"Ekološki protesti\", name it \"Environmental Protests\"\n",
    "- If articles are about \"Politička kriza\", name it \"Political Crisis\"\n",
    "\n",
    "Documents from cluster:\n",
    "{content}\n",
    "\n",
    "IMPORTANT: Respond ONLY with the English language cluster name, no Serbian words allowed.\n",
    "Example good responses: \"Economic Reform\", \"Infrastructure Development\", \"Criminal Investigation\"\n",
    "Example bad responses: \"Finansijski zakoni\", \"Ekološki protesti\", \"Politička kriza\" \"\"\"\n",
    "\n",
    "        # Try to get response with retries\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=\"claude-3-opus-20240229\",\n",
    "                    max_tokens=30,\n",
    "                    temperature=0.2,\n",
    "                    messages=[{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }]\n",
    "                )\n",
    "                \n",
    "                cluster_name = response.content[0].text.strip()\n",
    "                # Additional check to ensure the response is in English\n",
    "                if any(c.lower() in cluster_name.lower() for c in ['č', 'ć', 'š', 'ž', 'đ']):\n",
    "                    raise ValueError(\"Response contains Serbian characters\")\n",
    "                cluster_names[cluster_id] = cluster_name\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"Failed to get name for cluster {cluster_id}: {str(e)}\")\n",
    "                    cluster_names[cluster_id] = f\"Cluster {cluster_id}\"\n",
    "                else:\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "    \n",
    "    return cluster_names\n",
    "\n",
    "# Use the function\n",
    "try:\n",
    "    cluster_names = generate_cluster_names(results, anthropic)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nGenerated Cluster Names:\")\n",
    "    print(\"=\" * 50)\n",
    "    for cluster_id, name in cluster_names.items():\n",
    "        print(f\"\\nCluster {cluster_id}: {name}\")\n",
    "        print(\"-\" * 30)\n",
    "        # Print a few sample titles for reference\n",
    "        print(\"Sample titles:\")\n",
    "        for doc in results['representative_documents'][cluster_id][:2]:\n",
    "            print(f\"- {doc['title']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating cluster names: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Hospital Tragedy',\n",
       " 1: 'Crime and Security',\n",
       " 2: 'Criminal Code Amendments',\n",
       " 3: 'Savski Bridge Protests',\n",
       " 4: 'Workplace Accident',\n",
       " 5: 'Yugoslav Nostalgia',\n",
       " 6: 'Public Enterprises',\n",
       " 7: 'Police Recruitment'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summaries in English with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_news_report(\n",
    "    query: str,\n",
    "    collection,\n",
    "    model: SentenceTransformer,\n",
    "    anthropic_client: Anthropic,\n",
    "    language: str = \"English\",\n",
    "    top_k: int = 10,\n",
    "    max_retries: int = 3,\n",
    "    retry_delay: int = 2\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Perform semantic search and generate a news report based on top results.\n",
    "    Translates the query to Serbian before searching and generates report in specified language.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query in English\n",
    "        collection: MongoDB collection\n",
    "        model: Sentence transformer model for embeddings\n",
    "        anthropic_client: Anthropic client\n",
    "        language: Output language for the report\n",
    "        top_k: Number of top articles to consider\n",
    "        max_retries: Maximum number of API retries\n",
    "        retry_delay: Delay between retries in seconds\n",
    "    \n",
    "    Returns:\n",
    "        Generated news report\n",
    "    \"\"\"\n",
    "    # Translate query to Serbian using Claude\n",
    "    translation_prompt = f\"Translate the following {language} text to Serbian latin. Provide only the translation, nothing else: '{query}'\"\n",
    "    \n",
    "    try:\n",
    "        translation_response = anthropic_client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            max_tokens=100,\n",
    "            temperature=0,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": translation_prompt\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        serbian_query = translation_response.content[0].text.strip()\n",
    "        print(serbian_query)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Translation failed: {str(e)}\")\n",
    "    \n",
    "    # Generate embedding for Serbian query\n",
    "    query_embedding = model.encode(serbian_query).tolist()\n",
    "    \n",
    "    # Perform vector search\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 100,\n",
    "                \"limit\": top_k\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"title\": 1,\n",
    "                \"content\": 1,\n",
    "                \"date\": 1,\n",
    "                \"score\": { \"$meta\": \"vectorSearchScore\" }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = list(collection.aggregate(pipeline))\n",
    "    \n",
    "    # Prepare content for Claude\n",
    "    articles_text = \"\\n\\n\".join([\n",
    "        f\"Article {i+1}:\\nDate: {doc['date']}\\nTitle: {doc['title']}\\nContent: {doc['content'][:500]}...\"\n",
    "        for i, doc in enumerate(results)\n",
    "    ])\n",
    "    \n",
    "    # Create prompt for report generation\n",
    "    prompt = f\"\"\"You are an expert journalist and news analyst. Based on the following {top_k} most relevant Serbian news articles about \"{query}\" (translated to Serbian as \"{serbian_query}\"), \n",
    "create a concise, well-structured news report in {language}. The report should:\n",
    "- Be around 250-300 words\n",
    "- Start with a clear headline\n",
    "- Include key facts, dates, and relevant context\n",
    "- Maintain journalistic neutrality\n",
    "- Focus on the most newsworthy aspects\n",
    "- Include a brief conclusion or outlook\n",
    "Here are the articles:\n",
    "{articles_text}\n",
    "Please write the report in a professional journalistic style.\"\"\"\n",
    "\n",
    "    # Get response from Claude with retries\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = anthropic_client.messages.create(\n",
    "                model=\"claude-3-opus-20240229\",\n",
    "                max_tokens=1000,\n",
    "                temperature=0.3,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            report = response.content[0].text.strip()\n",
    "            return report\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise Exception(f\"Failed to generate report: {str(e)}\")\n",
    "            time.sleep(retry_delay)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investicije u rudarstvo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26db622b094421fbd0876b0806e7c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated News Report:\n",
      "================================================================================\n",
      "Headline: Serbia Seeks Investors for Privatization of Transport Company Lastra\n",
      "\n",
      "The Serbian Ministry of Economy has announced a public call for letters of interest in the privatization process of the transport company Lastra from Lazarevac. The majority shareholder of Lastra is the transport company Strela from Obrenovac, owning just over 77% of the capital, while the Serbian government, together with the Republic Pension and Disability Insurance Fund and the National Employment Service, holds the remaining 23% of shares.\n",
      "\n",
      "In other news, the Ministry of Justice has stated that it will clarify certain provisions of the Criminal Code that have received objections during the public debate. These provisions particularly relate to the introduction of a new criminal offense regarding the publication of materials that advise the commission of a criminal offense, the deletion of extortion of statements, and the article prescribing the criminal offense of abuse related to public procurement.\n",
      "\n",
      "Meanwhile, architect Slobodan Maldini has commented on the collapse of a part of the Railway Station in Novi Sad, which resulted in at least one fatality and several injuries. Maldini stated that the incident is a sign of negligence and carelessness during construction, emphasizing that even new constructions are collapsing in Serbia.\n",
      "\n",
      "The Minister of Internal Affairs, Ivica Dačić, has announced that a competition for 1,500 police officers has been announced, appealing to people to apply for the basic police training course. He noted that the greatest shortage of police officers is in Belgrade and Vojvodina and that those who successfully complete the nine-month training are guaranteed a secure job.\n",
      "\n",
      "In conclusion, the Serbian government is actively seeking investors for the privatization of state-owned companies, while also addressing issues in the justice system and public safety. The recent incidents, such as the collapse of the Railway Station in Novi Sad, highlight the need for improved construction standards and oversight in the country.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    # Example query\n",
    "    query = \"Investments in mining\"\n",
    "\n",
    "    report = generate_news_report(\n",
    "        query=query,\n",
    "        collection=collection,\n",
    "        model=model,\n",
    "        anthropic_client=anthropic,\n",
    "        top_k=10,\n",
    "        language=\"English\"\n",
    "\n",
    "    )\n",
    "\n",
    "    print(\"\\nGenerated News Report:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(report)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating report: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
